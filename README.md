# Kafkastore

Store kafka events from redis to kafka. These events are both click events
(generated by the [click tracker](https://github.com/adtekio/tracking.clicks))
and in-app events (generated by the
[in-app tracker](https://github.com/adtekio/tracking.inapp)).

The purpose is that, the kafkastore, does the heavy lifting instead of the
trackers:

- [device detection](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L34-L37)
- [geoip lookup](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L33)
- [event batching](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_inserter.rb#L25)

SSL Termination and load balancing is left to the trackers.

## Redis Event Format

The string that is pushed to redis is structured as follows (all values
are separeted by a single space):

```
<IP> <TIMESTAMP> <TOPIC> <EVENT TYPE> <QUERY STRING> <USER AGENT>
```

1. Request IP which is a country by this [code](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L33).
2. Timestamp in seconds since epoch when the request was recieved by the
   tracker.
3. Kafka topic to store the message.
4. Event type to store the kafka message with.
5. Original query string of the request
6. User agent is appended to the end. Note: the user agent
   can contain spaces, the user agent is assumed to be everything after query
   string. This is converted to device
   information [here](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L27).

If this format should change, then the [in-app tracker](https://github.com/adtekio/tracking.inapp/blob/448d1b81b921bf77896a467e15358bc6f022cc56/routes/tracking.rb#L11-L15)
needs updating, along with the [click tracker](https://github.com/adtekio/tracking.clicks/blob/985520904bf22b600edf45f21626430b1ae08d60/lib/click_handler.rb#L126).

## Kafka Message Format

The [message format](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_inserter.rb#L17-L21) is very simple for the following reasons:

- to make it easy for a consumer to determine whether it needs to handle
  the event ([path](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_inserter.rb#L20) is the event type and comes
  first).
- making it simple to [extend the message](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L29-L41)
  with more parameters in the future
- clear separation between meta details (i.e. the device and geoip information)
  and the original payload of the tracking event.
- human readable (i.e. string) making debugging that much easier.
- low computation to decode a message (i.e. using CGI encoding instead of JSON)

Of course, the assumption made here is that tracking calls will always be
simple in nature (i.e. not binary values) and the paramters will always be
key/value pairs (i.e. CGI/URL parameters). This might not be the case if post
requests are used for tracking events but that is out-of-scope here.

### Example

An example of a typical kafka message:

```
/t/ist bot_name&country=DE&device=smartphone&device_name=iPhone&ip=3160898477&klag=1&platform=ios&ts=1465287056 adid=ECC27E57-1605-2714-CCCC-13DC6DFB742E
```

1. First comes the event type, the actual type is assumed to be everything
   after the final '/' (slash).
2. Meta dataset, this is in the form of CGI encoded parameter/value pairs.
   The meta data is generated exclusively by the kafkastore and its values
   are based on the IP and user agent information. In addition, there is
   ```klag``` value the represents the time (in seconds) of how long the
   message waited in [redis before being pushed to kafka](https://github.com/adtekio/kafkastore/blob/a9e3670011c71fcc669a46e62df95d06683cae79/lib/batch_worker.rb#L32).
3. Query string of the original request. This is just passed through from
   the tracker, unmodified.

If this format should change, then the [consumers need updating](https://github.com/adtekio/consumers/blob/b71a17d9f8669f232036670c71c54adca6186ef3/lib/kafka/event.rb#L11). However this is only the case if the format changes
(i.e. ```<type> <meta> <params>```), not if there are extra "meta" or
"query" parameters included.

## Architecture

Similiar to how the [consumers](https://github.com/adtekio/consumers) are
started, here there is also a
[scheduler](https://github.com/adtekio/kafkastore/blob/master/lib/batch_scheduler.rb)
that is run as a [sidekiq](http://sidekiq.org) cron job. It regularly starts the
[kafka worker](https://github.com/adtekio/kafkastore/blob/master/lib/batch_worker.rb).
The worker in turn runs the [inserter](https://github.com/adtekio/kafkastore/blob/master/lib/batch_inserter.rb).

The difference here, the worker is given a batch size to pop off redis and
is only enqueued if there are redis events waiting in the queue.

## Scalability

Since redis is [single thread](http://redis.io/topics/faq), there is little
point in increasing the number of workers. Instead, to scale this, redeploy
to heroku as many kafkastores as necessary.

Each kafkastore deployment gets a new redis and the new redis can be
configured on the
[tracker side](https://github.com/adtekio/tracking.inapp/blob/f397a02d09cc11268deaf32edd70b8009894f7b8/app.json#L16-L21) (and [here](https://github.com/adtekio/tracking.clicks/blob/a12fe1dad1364c34c1856fdf599b9afb3e0ab0fe/app.json#L16-L21)), so that the trackers store events in
round robin way across all instances of the kafkastore code. Configuration
of new redis for the trackers does not require redeployment of the trackers.

The number of clickstores that can be configured for a tracker is not limited,
currently two are given as example, however ```_3```, ```_4```, etc are
possible.

## Development

Generate a ```.env``` and then fill it with values:

    prompt> rake appjson:to_dotenv
    prompt> $EDITOR .env

Start the worker and web frontend with:

    prompt> foreman start web
    prompt> foreman start worker

## Deployment

Easiest way to deploy this, is to use heroku!

[![Deploy To Heroku](https://www.herokucdn.com/deploy/button.png)](https://heroku.com/deploy?template=https://github.com/adtekio/kafkastore)

## Travis

[![Build Status](https://travis-ci.org/adtekio/kafkastore.svg?branch=master)](https://travis-ci.org/adtekio/kafkastore)
